# ğŸ¨ Neural Canvas

**Modern Language Model Training Framework**  
*Building state-of-the-art transformers from scratch with 2025 best practices*

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![Transformers](https://img.shields.io/badge/ğŸ¤—-Transformers-yellow.svg)](https://huggingface.co/transformers/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸš€ What is Neural Canvas?

Neural Canvas is a comprehensive deep learning project that implements **modern transformer architectures from scratch** and compares them against fine-tuned pre-trained models. Think of it as your personal AI training ground where you can experiment with cutting-edge NLP techniques without the black box.

### Why This Project Exists

Most people use pre-trained models without understanding what's under the hood. This project bridges that gap by:

- âœ¨ **Building a Llama-style transformer from scratch** (RoPE, RMSNorm, GQA, SwiGLU)
- ğŸ”¬ **Training on real-world datasets** (500K+ text samples)
- ğŸ“Š **Comparing custom models vs fine-tuned giants** (Fair benchmarking)
- ğŸŒ± **Tracking sustainability** (Carbon emissions, energy usage)
- ğŸ“ **Learning by doing** (Educational but production-ready)

---

## ğŸ—ï¸ Architecture Overview

### Model 1: Modern Transformer (Built from Scratch)

A 1.2B parameter transformer implementing 2025's best practices:

| Feature | What It Does | Why It Matters |
|---------|-------------|----------------|
| **RoPE** | Rotary Position Embeddings | Better position awareness than absolute embeddings |
| **RMSNorm** | Root Mean Square Normalization | More stable training than LayerNorm |
| **GQA** | Grouped Query Attention | Faster inference, less memory than MHA |
| **SwiGLU** | Gated Linear Units | Better expressiveness than standard FFN |

**Specs:**
- ğŸ§  **12 Layers**, 16 attention heads (4 KV heads)
- ğŸ“ **1024 hidden dimensions**, 2048 max sequence length
- ğŸ“¦ **500K training samples** from OpenWebText + C4
- â±ï¸ **30 epochs** with learning rate warmup and gradient clipping

### Model 2: Fine-Tuned Llama 2 (Baseline Comparison)

- ğŸ¦™ **Llama 2 7B** with 4-bit quantization (LoRA adapters)
- ğŸ¯ **Fine-tuned** on conversational datasets
- âš¡ **Efficient training** with PEFT (Parameter-Efficient Fine-Tuning)

---

## ğŸ“š Datasets

We train on large-scale, diverse text corpora:

| Dataset | Size | Purpose | License |
|---------|------|---------|---------|
| **OpenWebText** | 250K samples | General web knowledge | Open |
| **C4** | 250K samples | Clean crawled web text | Open |
| **WikiArt** | Optional | Creative descriptions | CC-BY |

**Total:** 500K+ high-quality training examples

---

## ğŸ› ï¸ Project Structure

```
neural-canvas/
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ modern_transformer.py    # Our transformer implementation
â”‚   â”‚   â”œâ”€â”€ transformer_model.py     # Base transformer
â”‚   â”‚   â””â”€â”€ conversational_agent.py  # Inference interface
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ train_model1.py          # Train from scratch
â”‚   â”‚   â”œâ”€â”€ train_model2.py          # Fine-tune Llama 2
â”‚   â”‚   â””â”€â”€ inference.py             # Chat with models
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ dataset_loader.py        # Data pipeline
â”‚       â”œâ”€â”€ model_evaluator.py       # Metrics & benchmarks
â”‚       â””â”€â”€ sustainability_tracker.py # Carbon tracking
â”œâ”€â”€ train.csh                        # Training launcher (csh)
â”œâ”€â”€ run_model1.csh                   # Quick start script
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ TRAINING.md                      # Detailed training guide
â””â”€â”€ README.md                        # You are here!
```

---

## âš¡ Quick Start

### 1ï¸âƒ£ **Setup Environment**

```bash
# Clone the repo
git clone https://github.com/MuhammadMaazA/neural-canvas.git
cd neural-canvas

# Create virtual environment
python3 -m venv venv
source venv/bin/activate.csh  # for csh users

# Install dependencies
pip install --upgrade pip
pip install -r requirements.txt

# Download NLTK data
python -c "import nltk; nltk.download('punkt'); nltk.download('wordnet')"
```

### 2ï¸âƒ£ **Train Model 1 (From Scratch)**

```csh
# Set cache directories (optional, for storage management)
setenv HF_HOME /cs/student/projects1/2023/muhamaaz/datasets
setenv HF_DATASETS_CACHE /cs/student/projects1/2023/muhamaaz/datasets

# Start training
cd llm/scripts
python train_model1.py
```

**Expected:**
- â±ï¸ **Training time:** 8-12 hours on A100 / 12-18 hours on RTX 3090 Ti
- ğŸ’¾ **Checkpoints:** Saved to `/checkpoints/model1_best.pt` (~800MB)
- ğŸ“Š **Logs:** Real-time training stats in `/logs/`

### 3ï¸âƒ£ **Train Model 2 (Fine-tune Llama)**

```csh
cd llm/scripts
python train_model2.py
```

**Expected:**
- â±ï¸ **Training time:** 4-6 hours on A100
- ğŸ’¾ **Memory:** ~16GB GPU with 4-bit quantization
- ğŸ“¦ **LoRA adapters:** ~50MB (not the full 7B model!)

### 4ï¸âƒ£ **Chat with Your Model**

```csh
cd llm/scripts
python inference.py --model model1
```

---

## ğŸ¯ Training in Background

Long training sessions? No problem! Keep your model training even after logout:

### Option 1: Using `nohup` (Simplest)

```csh
nohup ./train.csh >& training.log &
echo $! > training.pid

# Monitor progress
tail -f training.log

# Stop training
kill `cat training.pid`
```

### Option 2: Using `screen` (Recommended)

```csh
# Start screen session
screen -S training

# Run training
./train.csh

# Detach: Press Ctrl+A then D
# Reattach later: screen -r training
```

### Option 3: Using `tmux`

```csh
tmux new -s training
./train.csh
# Detach: Press Ctrl+B then D
# Reattach: tmux attach -t training
```

---

## ğŸ“Š Monitoring & Metrics

### GPU Usage

```bash
watch -n 1 nvidia-smi
```

### Training Metrics

We track:
- ğŸ“‰ **Loss** (cross-entropy)
- ğŸ¯ **Perplexity** (lower is better)
- ğŸŒ **Carbon emissions** (via CodeCarbon)
- âš¡ **Energy consumption** (kWh)
- â±ï¸ **Training speed** (samples/sec)

All metrics are logged to TensorBoard:

```bash
tensorboard --logdir logs/
```

---

## ğŸ§ª Evaluation & Benchmarks

### Automated Evaluation

```csh
cd llm/scripts
python -c "from utils.model_evaluator import evaluate_model; evaluate_model('model1')"
```

Metrics include:
- **ROUGE scores** (overlap with reference text)
- **BLEU scores** (translation quality)
- **Perplexity** (confidence of predictions)
- **Human evaluation** (manual quality checks)

---

## ğŸŒ± Sustainability Tracking

We care about the environment! Every training run tracks:

- ğŸŒ **COâ‚‚ emissions** (kg COâ‚‚eq)
- âš¡ **Energy consumed** (kWh)
- ğŸŒ³ **Trees needed to offset** (estimated)

Results saved to `logs/emissions.csv`

---

## ğŸ“ Learning Resources

### Key Papers Implemented

- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) - Original Transformer
- [RoFormer: Enhanced Transformer with Rotary Position Embedding](https://arxiv.org/abs/2104.09864) - RoPE
- [Root Mean Square Layer Normalization](https://arxiv.org/abs/1910.07467) - RMSNorm
- [GLU Variants Improve Transformer](https://arxiv.org/abs/2002.05202) - SwiGLU
- [Llama 2: Open Foundation Models](https://arxiv.org/abs/2307.09288) - GQA

### Tutorials

See `TRAINING.md` for detailed guides on:
- Storage management (handling large datasets)
- Checkpoint recovery (resume training)
- Hyperparameter tuning
- Debugging common errors

---

## ğŸ¤ Contributing

This is a learning project, but contributions are welcome! Feel free to:

- ğŸ› Report bugs via Issues
- ğŸ’¡ Suggest features
- ğŸ”§ Submit pull requests
- ğŸ“– Improve documentation

---

## ğŸ“ License

MIT License - See `LICENSE` file for details.

---

## ğŸ‘¤ Author

**Muhammad Maaz**  
ğŸ“§ mmaaz2005@hotmail.com  
ğŸ™ GitHub: [@MuhammadMaazA](https://github.com/MuhammadMaazA)

---

## ğŸ™ Acknowledgments

- ğŸ“ Built for academic exploration and learning
- ğŸ¤— Hugging Face for transformers library
- ğŸ”¥ PyTorch team for the framework
- ğŸŒ CodeCarbon for sustainability tracking
- ğŸ’» UCL CS Department for compute resources

---

**Happy Training! ğŸš€**

*"The best way to understand transformers is to build one yourself."*
